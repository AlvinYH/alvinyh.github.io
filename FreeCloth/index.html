<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>FreeCloth: Free-form Generation Enhances Challenging Clothed Human Modeling</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="FreeCloth: Free-form Generation Enhances Challenging Clothed Human Modeling" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">FreeCloth: Free-form Generation Enhances Challenging Clothed Human Modeling</h1>
            <div class="nerf_subheader_v2">Arxiv 2024</div>
            <div class="nerf_subheader_v2">
                <div>
                    <a href="https://alvinyh.github.io/" target="_blank" class="nerf_authors_v2">Hang Ye<span
                            class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a href="https://shirleymaxx.github.io/" target="_blank" class="nerf_authors_v2">Xiaoxuan Ma<span
                            class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a href="https://haici.cc/" target="_blank" class="nerf_authors_v2">Hai Ci<span
                            class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a href="https://wentao.live/" target="_blank" class="nerf_authors_v2">Wentao Zhu<span
                        class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a href="https://cfcs.pku.edu.cn/english/people/faculty/yizhouwang/index.htm" target="_blank" class="nerf_authors_v2">Yizhou Wang<span
                        class="text-span_nerf"></span></a>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2">Peking University</h1>
                </div>

                <div class="external-link">
                    <a class="btn" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="https://github.com/AlvinYH/FreeCloth" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code (Coming Soon) </a>
                    <!-- <a class="btn btn-large btn-light" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video (Coming Soon) </a> -->
                </div>

            </div>
        </div>

    </div>

    <div class="white_section_nerf  w-container" style="margin-bottom: 0px;">
        <img src="assets/images/teaser.png">
    </div>

    <div class="white_section_nerf  w-container" style="width: 65%; margin-top: -10px; margin-bottom: 40px;">
        <p> <strong>TL;DR:</strong> we propose to model clothed human with <strong>a novel hybrid framework</strong>, which combines the strengths of LBS-based deformation and <strong>free-form generation</strong>. 
            Our method effectively captures the intricate geometric details of <strong>loose clothing</strong>, achieving superior visual fidelity and realism, particularly on the most challenging cases.
        </p>
    </div>

    <div data-anchor="slide1" class="section nerf_section" style="margin-bottom: 30px;">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                Achieving realistic animated human avatars requires accurate modeling of pose-dependent clothing deformations. Existing 
                learning-based methods heavily rely on the Linear Blend Skinning (LBS) of minimally-clothed human models like SMPL to model 
                deformation. However, these methods struggle to handle loose clothing, such as long dresses, where the canonicalization process 
                becomes ill-defined when the clothing is far from the body, leading to disjointed and fragmented results. To overcome this limitation, 
                we propose a novel hybrid framework to model challenging clothed humans. Our core idea is to use dedicated strategies to model different 
                regions, depending on whether they are close to or distant from the body. Specifically, we segment the human body into three categories: unclothed, 
                deformed, and generated. We simply replicate unclothed regions that require no deformation. For deformed regions close to the body, we leverage LBS 
                to handle the deformation. As for the generated regions, which correspond to loose clothing areas, we introduce a novel free-form, part-aware generator to 
                model them, as they are less affected by movements. This free-form generation paradigm brings enhanced flexibility and expressiveness to our hybrid framework, 
                enabling it to capture the intricate geometric details of challenging loose clothing, such as skirts and dresses. Experimental results on the benchmark dataset 
                featuring loose clothing demonstrate that our method achieves state-of-the-art performance with superior visual fidelity and realism, particularly in the most 
                challenging cases.
                <br>
                <!-- <img  src="assets/images/overview.png"> -->
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf" style="margin-bottom: 5px;">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/pipeline.png">

            <p> Given an unclothed and posed body, and a specific garment type, our goal is to create a realistic clothed human. 
                We first <strong>segment the human parts into three different regions</strong>: unclothed parts (<span style="color: rgb(211, 173, 29);">yellow</span>) need no deformation, deformed
                parts (<span style="color: rgb(30, 93, 188);">blue</span>), and generated parts (<span style="color: rgb(92, 127, 17);">green</span>). The hybrid framework comprises two essential modules: 
                (1) <strong>an LBS-based local deformation network</strong> to obtain pose-dependent deformed points that are close to the human body, and (2) <strong>a free-form 
                generator</strong> that focuses on generating the more loose clothing regions. By merging the unclothed, deformed, and generated points, we ultimately 
                obtain the complete point cloud of a clothed human. 
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Comparison with state-of-the-art</h2>
        <div class="grid-container-1">
            <div>
                <video class="video" loop controls autoPlay muted src="assets/videos/felice.mov"></video>
            </div>
            <div>
                <video class="video" loop controls autoPlay muted src="assets/videos/christine.mov"></video>
            </div>
            <div>
                <video class="video" loop controls autoPlay muted src="assets/videos/janett.mov"></video>
                <img src="assets/images/title.png" style="margin-top: 0;">
            </div>
            <!-- <div>
                <video class="video" loop controls autoPlay muted src="assets/videos/anna.mov"></video>
            </div>
            <div>
                <video class="video" loop controls autoPlay muted src="assets/videos/beatrice.mov"></video>
                <img src="assets/images/title.png">
            </div> -->
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf" style="margin-bottom: 15px;">Qualitative Results</h2>
        <div class="grid-container-1" style="margin-bottom: 8px;">
            <img src="assets/images/sota.png">
        </div>
        <div class="grid-container-1">
            <a class="mybtn" href="gallery.html" role="button">
             More Results </a>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Perceptual Study</h2>
        <div class="grid-container-0">
            <img src="assets/images/user_study.png">
        </div>
        <p style="width: 95%; margin: 10px auto 40px;"> <strong>Perceptual study results</strong>. 
            Across all examples, <strong>63.4%</strong> of human users prefer our method over the baselines. Additionally, our model receives <strong>56%</strong> of the 
            votes from the GPT-4o model. These results highlight the significant superiority of our approach, particularly in handling the most challenging clothing.
        </p>
    </div>

<div class="white_section_nerf grey_container w-container">
<h2 class="grey-heading_nerf">BibTeX</h2>
<!-- <div class="bibtex">
    <pre><code>@article{sun2023dreamcraft3d,
  title={Dreamcraft3d: Hierarchical 3d generation with bootstrapped diffusion prior},
  author={Sun, Jingxiang and Zhang, Bo and Shao, Ruizhi and Wang, Lizhen and Liu, Wen and Xie, Zhenda and Liu, Yebin},
  journal={arXiv preprint arXiv:2310.16818},
  year={2023}
}</code></pre>
</div> -->
</div>


</body>
<footer>
    This project page is inspired by <a href="https://mrtornado24.github.io/DreamCraft3D/">DreamCraft3D</a>.
</footer>

</html>
